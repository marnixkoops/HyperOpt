{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian model-based hyperparameter optimization\n",
        "\n",
        "In this notebook I will try an automated hyperparameter approach using Bayesian optimization.\n",
        "Recent [results](http://proceedings.mlr.press/v28/bergstra13.pdf) suggest [Bayesian hyperparameter optimization](https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf) of machine learning models is more efficient than manual, random, or grid search with:\n",
        "\n",
        "- Better overall performance on the test set\n",
        "- Less time required for optimization\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will use the [HyperOpt](https://github.com/hyperopt/hyperopt) package because it is widely used.\n",
        "Tor run the optimization we need the following:\n",
        "\n",
        "- Objective function to minimize\n",
        "- Space over which to search hyperparameters\n",
        "- Algorithm for optimization\n",
        "- History of results\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import xgboost as xgb\n",
        "import hyperopt as hyper\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from timeit import default_timer as timer\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare dataframe for PO Netherlands\n",
        "df = pd.read_csv('data/products_ordered_bq_sub_features.csv')\n",
        "df = df.dropna()  # Drop future rows (no actuals)\n",
        "df['actual'] = df['actual'] - df['blacklist']  # Remove blacklisted orders from target\n",
        "df.drop('blacklist', axis=1, inplace=True)  # Drop blacklist feature\n",
        "df.drop('key_id', axis=1, inplace=True)  # Drop key_id feature (we only have NL=1)\n",
        "df.info()\n",
        "\n",
        "# Define data to be used for training (use 3 years)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df[df['date'] > '01-01-2016']\n",
        "df['date'].describe()\n",
        "\n",
        "# seasonality_dummy_columns = df.filter(regex=('^seasonality.*dummy.*$')).columns.values\n",
        "# seasonality_dom_columns = df.filter(regex=('^seasonality\\|day_of_month\\|$')).columns.values\n",
        "# holiday_columns = df.filter(regex=('.*holiday.*')).columns.values\n",
        "# closed_day_columns = df.filter(regex=('.*closed.*')).columns.values\n",
        "# training_columns = np.array([['date'], ['actual'], seasonality_dummy_columns,\n",
        "#                              seasonality_dom_columns, holiday_columns, closed_day_columns])\n",
        "# training_columns = [feature for array in training_columns for feature in array]  # Flatten list into single array\n",
        "# df = df[training_columns]  # Subset data to defined columns\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataframes for modeling\n",
        "features = [f for f in df.columns if f not in ['date', 'actual']]  # Define training features\n",
        "X, y = df[features], df['actual']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # Split into train/test\n",
        "X_train.shape, y_train.shape\n",
        "X_test.shape, y_test.shape\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define objective function to minimize\n",
        "def objective(params):\n",
        "    \"\"\"Objective function to optimize which is our XGBoost model\"\"\"\n",
        "    start_time = timer() # Keep track of training time\n",
        "    global ITERATION  # Keep track of evals\n",
        "    ITERATION += 1\n",
        "\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)  # Create XGBoost dataframes\n",
        "    dvalid = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "    # Make sure parameters that need to be integers are integers\n",
        "    for param_name in ['max_depth', 'subsample', 'min_child_weight']:\n",
        "        params[param_name] = int(params[param_name])\n",
        "\n",
        "    # params = {\n",
        "    #     'objective': 'reg:linear',\n",
        "    #     'learning_rate': 1,\n",
        "    #     'max_depth': 2,\n",
        "    #     'min_child_weight': 10,\n",
        "    #     'subsample': 1,\n",
        "    #     'gamma': 0.5,\n",
        "    #     'colsample_bytree': 1,\n",
        "    #     'eval_metric': 'rmse',\n",
        "    #     'nthread': 4,\n",
        "    #     'silent': 1}\n",
        "\n",
        "    # watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
        "    booster = xgb.train(params, dtrain)\n",
        "    predictions = booster.predict(dvalid)\n",
        "\n",
        "    loss = np.sqrt(mean_squared_error(y_test, predictions))  # Compute rmse of trail\n",
        "    # print('rmse: {:.5}'.format(loss))\n",
        "\n",
        "    run_time = timer() - start_time\n",
        "\n",
        "    return {'loss': loss, 'params': params, 'iteration': ITERATION, 'train_time': run_time, 'status': hyper.STATUS_OK}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define objective function to minimize\n",
        "def optimize(bayes_trials, evals):\n",
        "    \"\"\"Define hyperparameter search space and optimize it using TPE\"\"\"\n",
        "    search_space = {\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_boost_rounds' : hyper.hp.quniform('num_boost_rounds', 100, 1000, 1),\n",
        "        'learning_rate': hyper.hp.quniform('learning_rate', 0.01, 0.5, 0.025),\n",
        "        'max_depth': hyper.hp.quniform('max_depth', 1, 13, 1),\n",
        "        'min_child_weight': hyper.hp.quniform('min_child_weight', 1, 6, 1),\n",
        "        'subsample': hyper.hp.quniform('subsample', 0.7, 1, 0.5),\n",
        "        'gamma': hyper.hp.quniform('gamma', 0.5, 1, 0.05),\n",
        "        'colsample_bytree': hyper.hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
        "        'eval_metric': 'rmse',\n",
        "        'nthread': 4,\n",
        "        'silent': 1,\n",
        "        'verbose': -1}\n",
        "\n",
        "    result = hyper.fmin(fn=objective, space=search_space, algo=hyper.tpe.suggest, trials=bayes_trials, max_evals=evals,\n",
        "                        show_progressbar=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization\n",
        "ITERATION = 0\n",
        "bayes_trials = hyper.Trials()  # Object where history of search trails are stored\n",
        "optimize(bayes_trials, evals=10)  # Run Bayesian optimization\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check results\n",
        "bayes_trials_results = sorted(bayes_trials.results, key = lambda x: x['loss'])  # Sort the results by loss\n",
        "bayes_trials_results[1]  # Print results of optimal iteration"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/Library/Frameworks/Python.framework/Versions/3.6/bin/python3",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}